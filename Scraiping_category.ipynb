{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client.category\n",
    "collection = db.category_collection\n",
    "collection.delete_many({})\n",
    "\n",
    "all_list=[]\n",
    "\n",
    "def first(target_url):\n",
    "    r = requests.get(target_url)\n",
    "    bs = BeautifulSoup(r.text, \"lxml\")\n",
    "    return bs\n",
    "\n",
    "def second(Soup):\n",
    "    pass_name = []\n",
    "    pass_url = []\n",
    "    for b in Soup.find_all(\"ul\",class_=\"sub_categories\"):\n",
    "        for b1 in b.find_all(\"a\"):\n",
    "            href1 = b1.get(\"href\")\n",
    "            path1 = urljoin(cookpad_url, href1)\n",
    "            ex1 = b1.text\n",
    "            pass_name.append(ex1)\n",
    "            pass_url.append(path1)\n",
    "            \n",
    "    return pass_name,pass_url\n",
    "    \n",
    "\n",
    "def third(bSoup):\n",
    "    recipe_name = []\n",
    "    recipe_url = []\n",
    "    for be in bSoup.find_all(\"div\", class_=\"recipe-text\"):\n",
    "        bee = be.find(\"a\")\n",
    "        href2 = bee.get(\"href\")\n",
    "        path2 = urljoin(cookpad_url, href2)\n",
    "        ex2 = bee.text\n",
    "        recipe_name.append(ex2)\n",
    "        recipe_url.append(path2)\n",
    "    return recipe_name,recipe_url\n",
    "\n",
    "def fourth(i1):\n",
    "    count=first(i1).find(\"span\" ,class_=\"search_count\")\n",
    "    repatter = re.compile(',')\n",
    "    tx = re.sub(repatter, '', count.text)\n",
    "    rrepatter = re.compile('\\n')\n",
    "    txt = re.sub(rrepatter, '',tx)\n",
    "    return txt\n",
    "\n",
    "def fifth():\n",
    "    jufuku = collection.find_one({\"path\" : URL})\n",
    "    if not jufuku:\n",
    "        collection.insert_one({\n",
    "            \"level\" : n,\n",
    "            \"oya_category\" : matchObject.group(),\n",
    "            \"category_name\" : 名前,\n",
    "            \"recipe_count\" : cou,\n",
    "            \"category_number\" : maObject.group(),\n",
    "            \"path\" : URL,\n",
    "        })\n",
    "        \n",
    "#level_1\n",
    "cookpad_url = \"https://cookpad.com/category/list\"\n",
    "bs_cookpad = first(cookpad_url)\n",
    "\n",
    "regex = r'/category/\\d'\n",
    "level_1_url_list = []\n",
    "for a in bs_cookpad.find_all(\"div\", class_=\"root_category_title_wrapper\"):\n",
    "    ex = a.find(\"a\").text\n",
    "    for a1 in a.find_all(href=re.compile(regex)):\n",
    "        href = a1.get(\"href\")\n",
    "        path = urljoin(cookpad_url, href)\n",
    "        cou = fourth(path)\n",
    "        matchObject = re.search(r'[\\d]+',path)\n",
    "        level_1_url_list.append(path)\n",
    "        collection.insert_one({\n",
    "            \"level\" : \"1\",\n",
    "            \"oya_category\" : \"-1\",\n",
    "            \"category_name\" : ex,\n",
    "            \"recipe_count\" : cou,\n",
    "            \"category_number\" : matchObject.group(),\n",
    "            \"path\" : path,\n",
    "        })\n",
    "        print(\"1\", \"-1\",ex, cou, matchObject.group(), path)\n",
    "        time.sleep(1)\n",
    "        \n",
    "#level_2\n",
    "n = 2\n",
    "while n<6:\n",
    "    n = str(n)\n",
    "    URL_list = \"URL_list\"+n\n",
    "    URL_list=[]\n",
    "    for List in level_1_url_list:\n",
    "        x,y = second(first(List))\n",
    "        for (名前,URL) in zip(x,y):\n",
    "            if bool(first(URL).find(\"span\", class_=\"current_leaf_category\")) is True:\n",
    "                all_list.append(URL)\n",
    "                \n",
    "                matchObject = re.search(r'[\\d]+', List)\n",
    "                cou = fourth(URL)\n",
    "                maObject = re.search(r'[\\d]+',URL)\n",
    "                \n",
    "                fifth()\n",
    "                print(\"✫\"+n, matchObject.group(), 名前, cou, maObject.group(), URL)\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                URL_list.append(URL)\n",
    "                \n",
    "                matchObject = re.search(r'[\\d]+', List)\n",
    "                cou = fourth(URL)\n",
    "                maObject = re.search(r'[\\d]+',URL)\n",
    "                \n",
    "                fifth()\n",
    "                print(n, matchObject.group(), 名前, cou, maObject.group(), URL)\n",
    "                time.sleep(1)\n",
    "    level_1_url_list = URL_list\n",
    "    n = int(n)\n",
    "    n = n+1\n",
    "print(\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
